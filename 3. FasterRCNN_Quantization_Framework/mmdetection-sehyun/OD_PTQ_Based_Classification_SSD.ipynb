{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcd53803",
   "metadata": {},
   "source": [
    "# StaticÂ Quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76f2ed9",
   "metadata": {},
   "source": [
    "Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "baf62f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os    \n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eaab6f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_model_size(model):\n",
    "    torch.save(model.state_dict(), \"tmp.pt\")\n",
    "    print(\"%.2f MB\" %(os.path.getsize(\"tmp.pt\")/1e6))\n",
    "    os.remove('tmp.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ed471d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SSD(\n",
       "  (backbone): SSDFeatureExtractorVGG(\n",
       "    (features): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (6): ReLU(inplace=True)\n",
       "      (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (8): ReLU(inplace=True)\n",
       "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (11): ReLU(inplace=True)\n",
       "      (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (13): ReLU(inplace=True)\n",
       "      (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (15): ReLU(inplace=True)\n",
       "      (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "      (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (18): ReLU(inplace=True)\n",
       "      (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (20): ReLU(inplace=True)\n",
       "      (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (22): ReLU(inplace=True)\n",
       "    )\n",
       "    (extra): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (6): ReLU(inplace=True)\n",
       "        (7): Sequential(\n",
       "          (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "          (1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6))\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (4): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (3): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (3): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (3): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Sequential(\n",
       "        (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (anchor_generator): DefaultBoxGenerator(aspect_ratios=[[2], [2, 3], [2, 3], [2, 3], [2], [2]], clip=True, scales=[0.07, 0.15, 0.33, 0.51, 0.69, 0.87, 1.05], steps=[8, 16, 32, 64, 100, 300])\n",
       "  (head): SSDHead(\n",
       "    (classification_head): SSDClassificationHead(\n",
       "      (module_list): ModuleList(\n",
       "        (0): Conv2d(512, 364, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): Conv2d(1024, 546, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (2): Conv2d(512, 546, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): Conv2d(256, 546, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): Conv2d(256, 364, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (5): Conv2d(256, 364, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (regression_head): SSDRegressionHead(\n",
       "      (module_list): ModuleList(\n",
       "        (0): Conv2d(512, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): Conv2d(1024, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (2): Conv2d(512, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): Conv2d(256, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (5): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (transform): GeneralizedRCNNTransform(\n",
       "      Normalize(mean=[0.48235, 0.45882, 0.40784], std=[0.00392156862745098, 0.00392156862745098, 0.00392156862745098])\n",
       "      Resize(min_size=(300,), max_size=300, mode='bilinear')\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models.detection import SSD300_VGG16_Weights\n",
    "\n",
    "\n",
    "model = torchvision.models.detection.ssd300_vgg16(weights=SSD300_VGG16_Weights)\n",
    "model\n",
    "# model.eval()\n",
    "# x = [torch.rand(3, 300, 300), torch.rand(3, 500, 400)]\n",
    "# predictions = model(x)\n",
    "# predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e53d265",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoCo_TestDataset(Dataset):\n",
    "    def __init__(self, rootDir, folder, tf=None):\n",
    "        \"\"\"Dataset class for CoCo data\n",
    "\n",
    "        Args:\n",
    "            rootDir (str): path to directory containing CoCo image data\n",
    "            folder (str) : 'train' or 'val' folder\n",
    "            tf (optional): transformation to apply. Defaults to None\n",
    "        \"\"\"        \n",
    "        self.rootDir = rootDir\n",
    "        self.folder = folder\n",
    "        self.transform = tf\n",
    "\n",
    "        # read rgb image list\n",
    "        sourceImgFolder =  os.path.join(self.rootDir, self.folder)\n",
    "        self.sourceImgFiles  = [os.path.join(sourceImgFolder, x) for x in sorted(os.listdir(sourceImgFolder))]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sourceImgFiles)\n",
    "  \n",
    "    def __getitem__(self, index):\n",
    "        # read source image and convert to RGB, apply transform\n",
    "        sourceImage = cv2.imread(f\"{self.sourceImgFiles[index]}\", -1)\n",
    "        sourceImage = cv2.cvtColor(sourceImage, cv2.COLOR_BGR2RGB)\n",
    "        if self.transform is not None:\n",
    "            sourceImage = self.transform(sourceImage)\n",
    "\n",
    "        return sourceImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "479cab25",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        # transforms.Resize((320, 320)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.485, 0.56, 0.406), std=(0.229, 0.224, 0.225))\n",
    "        ])\n",
    "\n",
    "TEST_BATCH_SIZE = 1\n",
    "num_workers = 8\n",
    "\n",
    "# Creating Test set and Test Dataloaders\n",
    "test_set = CoCo_TestDataset(rootDir= 'data/coco/', folder='test2017_sub', tf = tf)\n",
    "# test_set = torch.utils.data.Subset(test_set, indices=np.arange(32))\n",
    "# test_loader  = DataLoader(test_set, batch_size=TEST_BATCH_SIZE)\n",
    "test_sampler = torch.utils.data.SequentialSampler(test_set)\n",
    "\n",
    "\n",
    "# train_sampler = torch.utils.data.RandomSampler(train_set)\n",
    "# test_sampler = torch.utils.data.SequentialSampler(test_set)\n",
    "\n",
    "# train_loader = torch.utils.data.DataLoader(\n",
    "#     dataset=train_set, batch_size=32,\n",
    "#     sampler=train_sampler, num_workers=num_workers)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset=test_set, batch_size=TEST_BATCH_SIZE,\n",
    "    sampler=test_sampler, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3afdcc",
   "metadata": {},
   "source": [
    "## 3. Fusion layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "210d2da4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SSD(\n",
       "  (backbone): SSDFeatureExtractorVGG(\n",
       "    (features): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (6): ReLU(inplace=True)\n",
       "      (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (8): ReLU(inplace=True)\n",
       "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (11): ReLU(inplace=True)\n",
       "      (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (13): ReLU(inplace=True)\n",
       "      (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (15): ReLU(inplace=True)\n",
       "      (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "      (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (18): ReLU(inplace=True)\n",
       "      (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (20): ReLU(inplace=True)\n",
       "      (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (22): ReLU(inplace=True)\n",
       "    )\n",
       "    (extra): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (6): ReLU(inplace=True)\n",
       "        (7): Sequential(\n",
       "          (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "          (1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6))\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (4): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (3): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (3): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (3): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Sequential(\n",
       "        (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (anchor_generator): DefaultBoxGenerator(aspect_ratios=[[2], [2, 3], [2, 3], [2, 3], [2], [2]], clip=True, scales=[0.07, 0.15, 0.33, 0.51, 0.69, 0.87, 1.05], steps=[8, 16, 32, 64, 100, 300])\n",
       "  (head): SSDHead(\n",
       "    (classification_head): SSDClassificationHead(\n",
       "      (module_list): ModuleList(\n",
       "        (0): Conv2d(512, 364, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): Conv2d(1024, 546, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (2): Conv2d(512, 546, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): Conv2d(256, 546, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): Conv2d(256, 364, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (5): Conv2d(256, 364, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (regression_head): SSDRegressionHead(\n",
       "      (module_list): ModuleList(\n",
       "        (0): Conv2d(512, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): Conv2d(1024, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (2): Conv2d(512, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): Conv2d(256, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (5): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (transform): GeneralizedRCNNTransform(\n",
       "      Normalize(mean=[0.48235, 0.45882, 0.40784], std=[0.00392156862745098, 0.00392156862745098, 0.00392156862745098])\n",
       "      Resize(min_size=(300,), max_size=300, mode='bilinear')\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "model_fp32 = copy.deepcopy(model)\n",
    "model_fp32.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec9846d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SSD(\n",
       "  (backbone): SSDFeatureExtractorVGG(\n",
       "    (features): Sequential(\n",
       "      (0): ConvReLU2d(\n",
       "        (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): Identity()\n",
       "      (2): ConvReLU2d(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Identity()\n",
       "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (5): ConvReLU2d(\n",
       "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "      (6): Identity()\n",
       "      (7): ConvReLU2d(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "      (8): Identity()\n",
       "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (10): ConvReLU2d(\n",
       "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "      (11): Identity()\n",
       "      (12): ConvReLU2d(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "      (13): Identity()\n",
       "      (14): ConvReLU2d(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "      (15): Identity()\n",
       "      (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "      (17): ConvReLU2d(\n",
       "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "      (18): Identity()\n",
       "      (19): ConvReLU2d(\n",
       "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "      (20): Identity()\n",
       "      (21): ConvReLU2d(\n",
       "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "      (22): Identity()\n",
       "    )\n",
       "    (extra): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (1): ConvReLU2d(\n",
       "          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Identity()\n",
       "        (3): ConvReLU2d(\n",
       "          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Identity()\n",
       "        (5): ConvReLU2d(\n",
       "          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "        (6): Identity()\n",
       "        (7): Sequential(\n",
       "          (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "          (1): ConvReLU2d(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6))\n",
       "            (1): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): Identity()\n",
       "          (3): ConvReLU2d(\n",
       "            (0): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (1): ReLU(inplace=True)\n",
       "          )\n",
       "          (4): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): ConvReLU2d(\n",
       "          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): Identity()\n",
       "        (2): ConvReLU2d(\n",
       "          (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Identity()\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): ConvReLU2d(\n",
       "          (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): Identity()\n",
       "        (2): ConvReLU2d(\n",
       "          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Identity()\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): ConvReLU2d(\n",
       "          (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): Identity()\n",
       "        (2): ConvReLU2d(\n",
       "          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Identity()\n",
       "      )\n",
       "      (4): Sequential(\n",
       "        (0): ConvReLU2d(\n",
       "          (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): Identity()\n",
       "        (2): ConvReLU2d(\n",
       "          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (anchor_generator): DefaultBoxGenerator(aspect_ratios=[[2], [2, 3], [2, 3], [2, 3], [2], [2]], clip=True, scales=[0.07, 0.15, 0.33, 0.51, 0.69, 0.87, 1.05], steps=[8, 16, 32, 64, 100, 300])\n",
       "  (head): SSDHead(\n",
       "    (classification_head): SSDClassificationHead(\n",
       "      (module_list): ModuleList(\n",
       "        (0): Conv2d(512, 364, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): Conv2d(1024, 546, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (2): Conv2d(512, 546, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): Conv2d(256, 546, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): Conv2d(256, 364, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (5): Conv2d(256, 364, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (regression_head): SSDRegressionHead(\n",
       "      (module_list): ModuleList(\n",
       "        (0): Conv2d(512, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): Conv2d(1024, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (2): Conv2d(512, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): Conv2d(256, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (5): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (transform): GeneralizedRCNNTransform(\n",
       "      Normalize(mean=[0.48235, 0.45882, 0.40784], std=[0.00392156862745098, 0.00392156862745098, 0.00392156862745098])\n",
       "      Resize(min_size=(300,), max_size=300, mode='bilinear')\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fuse the activations to preceding layers, where applicable.\n",
    "# This needs to be done manually depending on the model architecture.\n",
    "# Common fusions include `conv + relu` and `conv + batchnorm + relu`\n",
    "modules_to_fuse = [ \n",
    "    [\"backbone.features.0\", \"backbone.features.1\"],\n",
    "    [\"backbone.features.2\", \"backbone.features.3\"],\n",
    "    [\"backbone.features.5\", \"backbone.features.6\"],\n",
    "    [\"backbone.features.7\", \"backbone.features.8\"],\n",
    "    [\"backbone.features.10\", \"backbone.features.11\"],\n",
    "    [\"backbone.features.12\", \"backbone.features.13\"],\n",
    "    [\"backbone.features.14\", \"backbone.features.15\"],\n",
    "    [\"backbone.features.17\", \"backbone.features.18\"],\n",
    "    [\"backbone.features.19\", \"backbone.features.20\"],\n",
    "    [\"backbone.features.21\", \"backbone.features.22\"],\n",
    "    \n",
    "    [\"backbone.extra.0.1\", \"backbone.extra.0.2\"],\n",
    "    [\"backbone.extra.0.3\", \"backbone.extra.0.4\"],\n",
    "    [\"backbone.extra.0.5\", \"backbone.extra.0.6\"],\n",
    "    [\"backbone.extra.0.7.1\", \"backbone.extra.0.7.2\"],\n",
    "    [\"backbone.extra.0.7.3\", \"backbone.extra.0.7.4\"],\n",
    "    \n",
    "    [\"backbone.extra.1.0\", \"backbone.extra.1.1\"],\n",
    "    [\"backbone.extra.1.2\", \"backbone.extra.1.3\"],\n",
    "    \n",
    "    [\"backbone.extra.2.0\", \"backbone.extra.2.1\"],\n",
    "    [\"backbone.extra.2.2\", \"backbone.extra.2.3\"],\n",
    "\n",
    "    [\"backbone.extra.3.0\", \"backbone.extra.3.1\"],\n",
    "    [\"backbone.extra.3.2\", \"backbone.extra.3.3\"],\n",
    "\n",
    "    [\"backbone.extra.4.0\", \"backbone.extra.4.1\"],\n",
    "    [\"backbone.extra.4.2\", \"backbone.extra.4.3\"]\n",
    "\n",
    "    ]\n",
    "\n",
    "\n",
    "torch.quantization.fuse_modules(model_fp32, modules_to_fuse, inplace=True)\n",
    "model_fp32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84259d45",
   "metadata": {},
   "source": [
    "## fused model equivalence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a131f6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SSD(\n",
       "  (backbone): SSDFeatureExtractorVGG(\n",
       "    (features): Sequential(\n",
       "      (0): ConvReLU2d(\n",
       "        (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): Identity()\n",
       "      (2): ConvReLU2d(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Identity()\n",
       "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (5): ConvReLU2d(\n",
       "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "      (6): Identity()\n",
       "      (7): ConvReLU2d(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "      (8): Identity()\n",
       "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (10): ConvReLU2d(\n",
       "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "      (11): Identity()\n",
       "      (12): ConvReLU2d(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "      (13): Identity()\n",
       "      (14): ConvReLU2d(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "      (15): Identity()\n",
       "      (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "      (17): ConvReLU2d(\n",
       "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "      (18): Identity()\n",
       "      (19): ConvReLU2d(\n",
       "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "      (20): Identity()\n",
       "      (21): ConvReLU2d(\n",
       "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "      (22): Identity()\n",
       "    )\n",
       "    (extra): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (1): ConvReLU2d(\n",
       "          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Identity()\n",
       "        (3): ConvReLU2d(\n",
       "          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Identity()\n",
       "        (5): ConvReLU2d(\n",
       "          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "        (6): Identity()\n",
       "        (7): Sequential(\n",
       "          (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "          (1): ConvReLU2d(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6))\n",
       "            (1): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): Identity()\n",
       "          (3): ConvReLU2d(\n",
       "            (0): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (1): ReLU(inplace=True)\n",
       "          )\n",
       "          (4): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): ConvReLU2d(\n",
       "          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): Identity()\n",
       "        (2): ConvReLU2d(\n",
       "          (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Identity()\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): ConvReLU2d(\n",
       "          (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): Identity()\n",
       "        (2): ConvReLU2d(\n",
       "          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Identity()\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): ConvReLU2d(\n",
       "          (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): Identity()\n",
       "        (2): ConvReLU2d(\n",
       "          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Identity()\n",
       "      )\n",
       "      (4): Sequential(\n",
       "        (0): ConvReLU2d(\n",
       "          (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): Identity()\n",
       "        (2): ConvReLU2d(\n",
       "          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (anchor_generator): DefaultBoxGenerator(aspect_ratios=[[2], [2, 3], [2, 3], [2, 3], [2], [2]], clip=True, scales=[0.07, 0.15, 0.33, 0.51, 0.69, 0.87, 1.05], steps=[8, 16, 32, 64, 100, 300])\n",
       "  (head): SSDHead(\n",
       "    (classification_head): SSDClassificationHead(\n",
       "      (module_list): ModuleList(\n",
       "        (0): Conv2d(512, 364, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): Conv2d(1024, 546, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (2): Conv2d(512, 546, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): Conv2d(256, 546, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): Conv2d(256, 364, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (5): Conv2d(256, 364, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (regression_head): SSDRegressionHead(\n",
       "      (module_list): ModuleList(\n",
       "        (0): Conv2d(512, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): Conv2d(1024, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (2): Conv2d(512, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): Conv2d(256, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (5): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (transform): GeneralizedRCNNTransform(\n",
       "      Normalize(mean=[0.48235, 0.45882, 0.40784], std=[0.00392156862745098, 0.00392156862745098, 0.00392156862745098])\n",
       "      Resize(min_size=(300,), max_size=300, mode='bilinear')\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "model_fp32.eval()\n",
    "\n",
    "# assert helper.model_equivalence(model_1=model_fp32, model_2=fused_model_fp32, device=cuda_device, rtol=1e-05, atol=1e-05, num_tests=100, input_size=(1,3,320,320)), \"Fused model is not equivalent to the original model!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38dee100",
   "metadata": {},
   "source": [
    "## 4. StaticÂ Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d326ed2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.quantization import QuantStub, DeQuantStub\n",
    "\n",
    "class Quantizedmodel(nn.Module):\n",
    "    def __init__(self, model_fp32):\n",
    "        super(Quantizedmodel, self).__init__()\n",
    "        self.quant = QuantStub()\n",
    "        self.dequant = DeQuantStub()\n",
    "        self.model_fp32 = model_fp32\n",
    "    \n",
    "    def forward(self, x):        \n",
    "        # x = self.quant(x)\n",
    "        \n",
    "        # x = self.dequant(x)\n",
    "        x = self.model_fp32(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1e04957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calibrate_model(model, loader, device=torch.device(\"cpu:0\")):\n",
    "\n",
    "#     model.to(device)\n",
    "#     model.eval()\n",
    "\n",
    "#     for inputs, labels in loader:\n",
    "#         inputs = inputs.to(device)\n",
    "#         labels = labels.to(device)\n",
    "#         _ = model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "404e9dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibrate_model(model, loader, device=torch.device(\"cpu:0\")):\n",
    "    \n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    for inputs in tqdm(loader):\n",
    "\n",
    "      inputs = inputs[0].to(device)\n",
    "      inputs = inputs.unsqueeze(0) # create a mini-batch as expected by the model\n",
    "      _ = model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab06f857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SSD(\n",
       "  (backbone): SSDFeatureExtractorVGG(\n",
       "    (features): Sequential(\n",
       "      (0): ConvReLU2d(\n",
       "        (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): Identity()\n",
       "      (2): ConvReLU2d(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Identity()\n",
       "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (5): ConvReLU2d(\n",
       "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "      (6): Identity()\n",
       "      (7): ConvReLU2d(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "      (8): Identity()\n",
       "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (10): ConvReLU2d(\n",
       "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "      (11): Identity()\n",
       "      (12): ConvReLU2d(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "      (13): Identity()\n",
       "      (14): ConvReLU2d(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "      (15): Identity()\n",
       "      (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "      (17): ConvReLU2d(\n",
       "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "      (18): Identity()\n",
       "      (19): ConvReLU2d(\n",
       "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "      (20): Identity()\n",
       "      (21): ConvReLU2d(\n",
       "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "      (22): Identity()\n",
       "    )\n",
       "    (extra): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (1): ConvReLU2d(\n",
       "          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Identity()\n",
       "        (3): ConvReLU2d(\n",
       "          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Identity()\n",
       "        (5): ConvReLU2d(\n",
       "          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "        (6): Identity()\n",
       "        (7): Sequential(\n",
       "          (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "          (1): ConvReLU2d(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6))\n",
       "            (1): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): Identity()\n",
       "          (3): ConvReLU2d(\n",
       "            (0): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (1): ReLU(inplace=True)\n",
       "          )\n",
       "          (4): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): ConvReLU2d(\n",
       "          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): Identity()\n",
       "        (2): ConvReLU2d(\n",
       "          (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Identity()\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): ConvReLU2d(\n",
       "          (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): Identity()\n",
       "        (2): ConvReLU2d(\n",
       "          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Identity()\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): ConvReLU2d(\n",
       "          (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): Identity()\n",
       "        (2): ConvReLU2d(\n",
       "          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Identity()\n",
       "      )\n",
       "      (4): Sequential(\n",
       "        (0): ConvReLU2d(\n",
       "          (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): Identity()\n",
       "        (2): ConvReLU2d(\n",
       "          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (anchor_generator): DefaultBoxGenerator(aspect_ratios=[[2], [2, 3], [2, 3], [2, 3], [2], [2]], clip=True, scales=[0.07, 0.15, 0.33, 0.51, 0.69, 0.87, 1.05], steps=[8, 16, 32, 64, 100, 300])\n",
       "  (head): SSDHead(\n",
       "    (classification_head): SSDClassificationHead(\n",
       "      (module_list): ModuleList(\n",
       "        (0): Conv2d(512, 364, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): Conv2d(1024, 546, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (2): Conv2d(512, 546, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): Conv2d(256, 546, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): Conv2d(256, 364, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (5): Conv2d(256, 364, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (regression_head): SSDRegressionHead(\n",
       "      (module_list): ModuleList(\n",
       "        (0): Conv2d(512, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): Conv2d(1024, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (2): Conv2d(512, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): Conv2d(256, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (5): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (transform): GeneralizedRCNNTransform(\n",
       "      Normalize(mean=[0.48235, 0.45882, 0.40784], std=[0.00392156862745098, 0.00392156862745098, 0.00392156862745098])\n",
       "      Resize(min_size=(300,), max_size=300, mode='bilinear')\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_fp32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d67ac46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Quantizedmodel(\n",
       "  (quant): QuantStub(\n",
       "    (activation_post_process): HistogramObserver()\n",
       "  )\n",
       "  (dequant): DeQuantStub()\n",
       "  (model_fp32): SSD(\n",
       "    (backbone): SSDFeatureExtractorVGG(\n",
       "      (features): Sequential(\n",
       "        (0): ConvReLU2d(\n",
       "          (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (activation_post_process): HistogramObserver()\n",
       "        )\n",
       "        (1): Identity()\n",
       "        (2): ConvReLU2d(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (activation_post_process): HistogramObserver()\n",
       "        )\n",
       "        (3): Identity()\n",
       "        (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (5): ConvReLU2d(\n",
       "          (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (activation_post_process): HistogramObserver()\n",
       "        )\n",
       "        (6): Identity()\n",
       "        (7): ConvReLU2d(\n",
       "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (activation_post_process): HistogramObserver()\n",
       "        )\n",
       "        (8): Identity()\n",
       "        (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (10): ConvReLU2d(\n",
       "          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (activation_post_process): HistogramObserver()\n",
       "        )\n",
       "        (11): Identity()\n",
       "        (12): ConvReLU2d(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (activation_post_process): HistogramObserver()\n",
       "        )\n",
       "        (13): Identity()\n",
       "        (14): ConvReLU2d(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (activation_post_process): HistogramObserver()\n",
       "        )\n",
       "        (15): Identity()\n",
       "        (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "        (17): ConvReLU2d(\n",
       "          (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (activation_post_process): HistogramObserver()\n",
       "        )\n",
       "        (18): Identity()\n",
       "        (19): ConvReLU2d(\n",
       "          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (activation_post_process): HistogramObserver()\n",
       "        )\n",
       "        (20): Identity()\n",
       "        (21): ConvReLU2d(\n",
       "          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (activation_post_process): HistogramObserver()\n",
       "        )\n",
       "        (22): Identity()\n",
       "      )\n",
       "      (extra): ModuleList(\n",
       "        (0): Sequential(\n",
       "          (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (1): ConvReLU2d(\n",
       "            (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (1): ReLU(inplace=True)\n",
       "            (activation_post_process): HistogramObserver()\n",
       "          )\n",
       "          (2): Identity()\n",
       "          (3): ConvReLU2d(\n",
       "            (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (1): ReLU(inplace=True)\n",
       "            (activation_post_process): HistogramObserver()\n",
       "          )\n",
       "          (4): Identity()\n",
       "          (5): ConvReLU2d(\n",
       "            (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (1): ReLU(inplace=True)\n",
       "            (activation_post_process): HistogramObserver()\n",
       "          )\n",
       "          (6): Identity()\n",
       "          (7): Sequential(\n",
       "            (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "            (1): ConvReLU2d(\n",
       "              (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (activation_post_process): HistogramObserver()\n",
       "            )\n",
       "            (2): Identity()\n",
       "            (3): ConvReLU2d(\n",
       "              (0): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (activation_post_process): HistogramObserver()\n",
       "            )\n",
       "            (4): Identity()\n",
       "          )\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): ConvReLU2d(\n",
       "            (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (1): ReLU(inplace=True)\n",
       "            (activation_post_process): HistogramObserver()\n",
       "          )\n",
       "          (1): Identity()\n",
       "          (2): ConvReLU2d(\n",
       "            (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "            (1): ReLU(inplace=True)\n",
       "            (activation_post_process): HistogramObserver()\n",
       "          )\n",
       "          (3): Identity()\n",
       "        )\n",
       "        (2): Sequential(\n",
       "          (0): ConvReLU2d(\n",
       "            (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (1): ReLU(inplace=True)\n",
       "            (activation_post_process): HistogramObserver()\n",
       "          )\n",
       "          (1): Identity()\n",
       "          (2): ConvReLU2d(\n",
       "            (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "            (1): ReLU(inplace=True)\n",
       "            (activation_post_process): HistogramObserver()\n",
       "          )\n",
       "          (3): Identity()\n",
       "        )\n",
       "        (3): Sequential(\n",
       "          (0): ConvReLU2d(\n",
       "            (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (1): ReLU(inplace=True)\n",
       "            (activation_post_process): HistogramObserver()\n",
       "          )\n",
       "          (1): Identity()\n",
       "          (2): ConvReLU2d(\n",
       "            (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "            (1): ReLU(inplace=True)\n",
       "            (activation_post_process): HistogramObserver()\n",
       "          )\n",
       "          (3): Identity()\n",
       "        )\n",
       "        (4): Sequential(\n",
       "          (0): ConvReLU2d(\n",
       "            (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (1): ReLU(inplace=True)\n",
       "            (activation_post_process): HistogramObserver()\n",
       "          )\n",
       "          (1): Identity()\n",
       "          (2): ConvReLU2d(\n",
       "            (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "            (1): ReLU(inplace=True)\n",
       "            (activation_post_process): HistogramObserver()\n",
       "          )\n",
       "          (3): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (anchor_generator): DefaultBoxGenerator(aspect_ratios=[[2], [2, 3], [2, 3], [2, 3], [2], [2]], clip=True, scales=[0.07, 0.15, 0.33, 0.51, 0.69, 0.87, 1.05], steps=[8, 16, 32, 64, 100, 300])\n",
       "    (head): SSDHead(\n",
       "      (classification_head): SSDClassificationHead(\n",
       "        (module_list): ModuleList(\n",
       "          (0): Conv2d(\n",
       "            512, 364, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (activation_post_process): HistogramObserver()\n",
       "          )\n",
       "          (1): Conv2d(\n",
       "            1024, 546, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (activation_post_process): HistogramObserver()\n",
       "          )\n",
       "          (2): Conv2d(\n",
       "            512, 546, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (activation_post_process): HistogramObserver()\n",
       "          )\n",
       "          (3): Conv2d(\n",
       "            256, 546, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (activation_post_process): HistogramObserver()\n",
       "          )\n",
       "          (4): Conv2d(\n",
       "            256, 364, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (activation_post_process): HistogramObserver()\n",
       "          )\n",
       "          (5): Conv2d(\n",
       "            256, 364, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (activation_post_process): HistogramObserver()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (regression_head): SSDRegressionHead(\n",
       "        (module_list): ModuleList(\n",
       "          (0): Conv2d(\n",
       "            512, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (activation_post_process): HistogramObserver()\n",
       "          )\n",
       "          (1): Conv2d(\n",
       "            1024, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (activation_post_process): HistogramObserver()\n",
       "          )\n",
       "          (2): Conv2d(\n",
       "            512, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (activation_post_process): HistogramObserver()\n",
       "          )\n",
       "          (3): Conv2d(\n",
       "            256, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (activation_post_process): HistogramObserver()\n",
       "          )\n",
       "          (4): Conv2d(\n",
       "            256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (activation_post_process): HistogramObserver()\n",
       "          )\n",
       "          (5): Conv2d(\n",
       "            256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (activation_post_process): HistogramObserver()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (transform): GeneralizedRCNNTransform(\n",
       "        Normalize(mean=[0.48235, 0.45882, 0.40784], std=[0.00392156862745098, 0.00392156862745098, 0.00392156862745098])\n",
       "        Resize(min_size=(300,), max_size=300, mode='bilinear')\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quantization Model Define\n",
    "quantized_model = Quantizedmodel(model_fp32=model_fp32)\n",
    "\n",
    "# Quantization Configuration Define\n",
    "quantized_model.qconfig = torch.quantization.get_default_qconfig('fbgemm')     # 'qnnpack' for NVIDIA\n",
    "torch.quantization.prepare(quantized_model, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c18958c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_device = torch.device(\"cuda:0\")\n",
    "cpu_device = torch.device(\"cpu:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84c1163f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 20/20 [00:04<00:00,  4.77it/s]\n"
     ]
    }
   ],
   "source": [
    "# Calibration\n",
    "calibrate_model(model=quantized_model, loader=test_loader, device=cpu_device)\n",
    "quantized_model = quantized_model.to(cpu_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "610c46a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantizedmodel(\n",
      "  (quant): Quantize(scale=tensor([1.]), zero_point=tensor([0]), dtype=torch.quint8)\n",
      "  (dequant): DeQuantize()\n",
      "  (model_fp32): SSD(\n",
      "    (backbone): SSDFeatureExtractorVGG(\n",
      "      (features): Sequential(\n",
      "        (0): QuantizedConvReLU2d(3, 64, kernel_size=(3, 3), stride=(1, 1), scale=18.992958068847656, zero_point=0, padding=(1, 1))\n",
      "        (1): Identity()\n",
      "        (2): QuantizedConvReLU2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=132.3282012939453, zero_point=0, padding=(1, 1))\n",
      "        (3): Identity()\n",
      "        (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (5): QuantizedConvReLU2d(64, 128, kernel_size=(3, 3), stride=(1, 1), scale=127.04178619384766, zero_point=0, padding=(1, 1))\n",
      "        (6): Identity()\n",
      "        (7): QuantizedConvReLU2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=109.63899230957031, zero_point=0, padding=(1, 1))\n",
      "        (8): Identity()\n",
      "        (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (10): QuantizedConvReLU2d(128, 256, kernel_size=(3, 3), stride=(1, 1), scale=122.65287017822266, zero_point=0, padding=(1, 1))\n",
      "        (11): Identity()\n",
      "        (12): QuantizedConvReLU2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=99.55809783935547, zero_point=0, padding=(1, 1))\n",
      "        (13): Identity()\n",
      "        (14): QuantizedConvReLU2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=53.7955436706543, zero_point=0, padding=(1, 1))\n",
      "        (15): Identity()\n",
      "        (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "        (17): QuantizedConvReLU2d(256, 512, kernel_size=(3, 3), stride=(1, 1), scale=27.91818618774414, zero_point=0, padding=(1, 1))\n",
      "        (18): Identity()\n",
      "        (19): QuantizedConvReLU2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=15.507092475891113, zero_point=0, padding=(1, 1))\n",
      "        (20): Identity()\n",
      "        (21): QuantizedConvReLU2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=7.84536600112915, zero_point=0, padding=(1, 1))\n",
      "        (22): Identity()\n",
      "      )\n",
      "      (extra): ModuleList(\n",
      "        (0): Sequential(\n",
      "          (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "          (1): QuantizedConvReLU2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=5.564229965209961, zero_point=0, padding=(1, 1))\n",
      "          (2): Identity()\n",
      "          (3): QuantizedConvReLU2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=2.534745931625366, zero_point=0, padding=(1, 1))\n",
      "          (4): Identity()\n",
      "          (5): QuantizedConvReLU2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=1.5578504800796509, zero_point=0, padding=(1, 1))\n",
      "          (6): Identity()\n",
      "          (7): Sequential(\n",
      "            (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "            (1): QuantizedConvReLU2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), scale=0.6239748001098633, zero_point=0, padding=(6, 6), dilation=(6, 6))\n",
      "            (2): Identity()\n",
      "            (3): QuantizedConvReLU2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), scale=0.18351754546165466, zero_point=0)\n",
      "            (4): Identity()\n",
      "          )\n",
      "        )\n",
      "        (1): Sequential(\n",
      "          (0): QuantizedConvReLU2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), scale=0.18464359641075134, zero_point=0)\n",
      "          (1): Identity()\n",
      "          (2): QuantizedConvReLU2d(256, 512, kernel_size=(3, 3), stride=(2, 2), scale=0.17813538014888763, zero_point=0, padding=(1, 1))\n",
      "          (3): Identity()\n",
      "        )\n",
      "        (2): Sequential(\n",
      "          (0): QuantizedConvReLU2d(512, 128, kernel_size=(1, 1), stride=(1, 1), scale=0.23479051887989044, zero_point=0)\n",
      "          (1): Identity()\n",
      "          (2): QuantizedConvReLU2d(128, 256, kernel_size=(3, 3), stride=(2, 2), scale=0.2993617057800293, zero_point=0, padding=(1, 1))\n",
      "          (3): Identity()\n",
      "        )\n",
      "        (3): Sequential(\n",
      "          (0): QuantizedConvReLU2d(256, 128, kernel_size=(1, 1), stride=(1, 1), scale=0.23344926536083221, zero_point=0)\n",
      "          (1): Identity()\n",
      "          (2): QuantizedConvReLU2d(128, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.22172392904758453, zero_point=0)\n",
      "          (3): Identity()\n",
      "        )\n",
      "        (4): Sequential(\n",
      "          (0): QuantizedConvReLU2d(256, 128, kernel_size=(1, 1), stride=(1, 1), scale=0.20649677515029907, zero_point=0)\n",
      "          (1): Identity()\n",
      "          (2): QuantizedConvReLU2d(128, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.30082905292510986, zero_point=0)\n",
      "          (3): Identity()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (anchor_generator): DefaultBoxGenerator(aspect_ratios=[[2], [2, 3], [2, 3], [2, 3], [2], [2]], clip=True, scales=[0.07, 0.15, 0.33, 0.51, 0.69, 0.87, 1.05], steps=[8, 16, 32, 64, 100, 300])\n",
      "    (head): SSDHead(\n",
      "      (classification_head): SSDClassificationHead(\n",
      "        (module_list): ModuleList(\n",
      "          (0): QuantizedConv2d(512, 364, kernel_size=(3, 3), stride=(1, 1), scale=0.0904959887266159, zero_point=21, padding=(1, 1))\n",
      "          (1): QuantizedConv2d(1024, 546, kernel_size=(3, 3), stride=(1, 1), scale=0.597994327545166, zero_point=33, padding=(1, 1))\n",
      "          (2): QuantizedConv2d(512, 546, kernel_size=(3, 3), stride=(1, 1), scale=0.5558974146842957, zero_point=39, padding=(1, 1))\n",
      "          (3): QuantizedConv2d(256, 546, kernel_size=(3, 3), stride=(1, 1), scale=0.45558497309684753, zero_point=38, padding=(1, 1))\n",
      "          (4): QuantizedConv2d(256, 364, kernel_size=(3, 3), stride=(1, 1), scale=0.5081186294555664, zero_point=52, padding=(1, 1))\n",
      "          (5): QuantizedConv2d(256, 364, kernel_size=(3, 3), stride=(1, 1), scale=0.40895819664001465, zero_point=53, padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (regression_head): SSDRegressionHead(\n",
      "        (module_list): ModuleList(\n",
      "          (0): QuantizedConv2d(512, 16, kernel_size=(3, 3), stride=(1, 1), scale=0.13793744146823883, zero_point=100, padding=(1, 1))\n",
      "          (1): QuantizedConv2d(1024, 24, kernel_size=(3, 3), stride=(1, 1), scale=0.1686946004629135, zero_point=68, padding=(1, 1))\n",
      "          (2): QuantizedConv2d(512, 24, kernel_size=(3, 3), stride=(1, 1), scale=0.15247716009616852, zero_point=75, padding=(1, 1))\n",
      "          (3): QuantizedConv2d(256, 24, kernel_size=(3, 3), stride=(1, 1), scale=0.11124643683433533, zero_point=64, padding=(1, 1))\n",
      "          (4): QuantizedConv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), scale=0.09099070727825165, zero_point=63, padding=(1, 1))\n",
      "          (5): QuantizedConv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), scale=0.07262507826089859, zero_point=77, padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (transform): GeneralizedRCNNTransform(\n",
      "        Normalize(mean=[0.48235, 0.45882, 0.40784], std=[0.00392156862745098, 0.00392156862745098, 0.00392156862745098])\n",
      "        Resize(min_size=(300,), max_size=300, mode='bilinear')\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Quantization Completed\n",
    "quantized_model_int8 = torch.quantization.convert(quantized_model, inplace=True)\n",
    "quantized_model_int8.eval()\n",
    "print(quantized_model_int8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410b759e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3fc685b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142.59 MB\n",
      "35.92 MB\n"
     ]
    }
   ],
   "source": [
    "print_model_size(model)\n",
    "print_model_size(quantized_model_int8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c565212",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "953f7fa2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Could not run 'quantized::conv2d_relu.new' with arguments from the 'CPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'quantized::conv2d_relu.new' is only available for these backends: [Negative, UNKNOWN_TENSOR_TYPE_ID, QuantizedXPU, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, SparseCPU, SparseCUDA, SparseHIP, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, SparseVE, UNKNOWN_TENSOR_TYPE_ID, NestedTensorCUDA, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID].\n\nQuantizedCPU: registered at ../aten/src/ATen/native/quantized/cpu/qconv.cpp:1423 [kernel]\nBackendSelect: fallthrough registered at ../aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:133 [backend fallback]\nNamed: registered at ../aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at ../aten/src/ATen/ConjugateFallback.cpp:18 [backend fallback]\nNegative: registered at ../aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\nZeroTensor: registered at ../aten/src/ATen/ZeroTensorFallback.cpp:86 [backend fallback]\nADInplaceOrView: fallthrough registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:64 [backend fallback]\nAutogradOther: fallthrough registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:35 [backend fallback]\nAutogradCPU: fallthrough registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:39 [backend fallback]\nAutogradCUDA: fallthrough registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:47 [backend fallback]\nAutogradXLA: fallthrough registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:51 [backend fallback]\nAutogradMPS: fallthrough registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:59 [backend fallback]\nAutogradXPU: fallthrough registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:43 [backend fallback]\nAutogradHPU: fallthrough registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:68 [backend fallback]\nAutogradLazy: fallthrough registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:55 [backend fallback]\nTracer: registered at ../torch/csrc/autograd/TraceTypeManual.cpp:295 [backend fallback]\nAutocastCPU: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:481 [backend fallback]\nAutocast: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:324 [backend fallback]\nBatched: registered at ../aten/src/ATen/BatchingRegistrations.cpp:1064 [backend fallback]\nVmapMode: fallthrough registered at ../aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\nFunctionalize: registered at ../aten/src/ATen/FunctionalizeFallbackKernel.cpp:89 [backend fallback]\nPythonTLSSnapshot: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:137 [backend fallback]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_28368/4279967637.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcpu_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mquantized_model_int8\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_28368/1496621207.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# x = self.dequant(x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_fp32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torchvision/models/detection/ssd.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, images, targets)\u001b[0m\n\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0;31m# get the features from the backbone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackbone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m             \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"0\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torchvision/models/detection/ssd.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    537\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m         \u001b[0;31m# L2 regularization + Rescaling of 1st block's feature map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 539\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    540\u001b[0m         \u001b[0mrescaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_weight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mrescaled\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/intrinsic/quantized/modules/conv_relu.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     91\u001b[0m                           mode=self.padding_mode)\n\u001b[1;32m     92\u001b[0m         return torch.ops.quantized.conv2d_relu(\n\u001b[0;32m---> 93\u001b[0;31m             input, self._packed_params, self.scale, self.zero_point)\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;31m# We save the function ptr as the `op` attribute on\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;31m# OpOverloadPacket to access it here.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;31m# TODO: use this to make a __dir__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Could not run 'quantized::conv2d_relu.new' with arguments from the 'CPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'quantized::conv2d_relu.new' is only available for these backends: [Negative, UNKNOWN_TENSOR_TYPE_ID, QuantizedXPU, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, SparseCPU, SparseCUDA, SparseHIP, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, SparseVE, UNKNOWN_TENSOR_TYPE_ID, NestedTensorCUDA, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID].\n\nQuantizedCPU: registered at ../aten/src/ATen/native/quantized/cpu/qconv.cpp:1423 [kernel]\nBackendSelect: fallthrough registered at ../aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:133 [backend fallback]\nNamed: registered at ../aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at ../aten/src/ATen/ConjugateFallback.cpp:18 [backend fallback]\nNegative: registered at ../aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\nZeroTensor: registered at ../aten/src/ATen/ZeroTensorFallback.cpp:86 [backend fallback]\nADInplaceOrView: fallthrough registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:64 [backend fallback]\nAutogradOther: fallthrough registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:35 [backend fallback]\nAutogradCPU: fallthrough registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:39 [backend fallback]\nAutogradCUDA: fallthrough registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:47 [backend fallback]\nAutogradXLA: fallthrough registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:51 [backend fallback]\nAutogradMPS: fallthrough registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:59 [backend fallback]\nAutogradXPU: fallthrough registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:43 [backend fallback]\nAutogradHPU: fallthrough registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:68 [backend fallback]\nAutogradLazy: fallthrough registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:55 [backend fallback]\nTracer: registered at ../torch/csrc/autograd/TraceTypeManual.cpp:295 [backend fallback]\nAutocastCPU: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:481 [backend fallback]\nAutocast: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:324 [backend fallback]\nBatched: registered at ../aten/src/ATen/BatchingRegistrations.cpp:1064 [backend fallback]\nVmapMode: fallthrough registered at ../aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\nFunctionalize: registered at ../aten/src/ATen/FunctionalizeFallbackKernel.cpp:89 [backend fallback]\nPythonTLSSnapshot: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:137 [backend fallback]\n"
     ]
    }
   ],
   "source": [
    "from data.util import  read_image\n",
    "\n",
    "model.eval()\n",
    "quantized_model_int8.eval()\n",
    "\n",
    "imgs = read_image('misc/demo2.jpg')\n",
    "imgs = torch.from_numpy(imgs)[None]\n",
    "imgs.to(cpu_device)\n",
    "\n",
    "quantized_model_int8(imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01883660",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7873a355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'boxes': tensor([[  5.5650,   1.2811, 297.4328, 294.3029],\n",
       "          [ 68.5410,   2.1247, 223.9397,  89.3615],\n",
       "          [ 27.9329,   7.7210, 121.7162, 144.6143],\n",
       "          [ 70.2444,   5.3549, 258.7443, 179.7451],\n",
       "          [103.4997,  34.8510, 220.3155, 276.7411],\n",
       "          [  9.5837,   1.7827, 295.3752, 296.3570],\n",
       "          [  8.9762,   1.8686, 154.3551,  92.3048],\n",
       "          [ 68.7176,  10.4747, 154.2110, 144.5562],\n",
       "          [  6.8083,   0.0000, 296.3820, 295.5557],\n",
       "          [  0.9061,  28.9066,  92.6611, 285.9233],\n",
       "          [107.3213,   6.1443, 181.6549, 158.8449],\n",
       "          [139.8574,  45.8880, 300.0000, 261.7556],\n",
       "          [132.3773,  10.6286, 219.7238, 146.5825],\n",
       "          [  9.2775,  53.1377, 179.9628, 254.6997],\n",
       "          [ 78.8346,  32.2352, 216.1662, 119.8140],\n",
       "          [168.7235,   3.3175, 246.2312, 158.1704],\n",
       "          [  6.8083,   0.0000, 296.3820, 295.5557],\n",
       "          [ 44.3411,  60.8006, 113.4774, 221.1278],\n",
       "          [115.8170,  19.1909, 190.4655,  93.6851],\n",
       "          [ 84.0293,  19.2286, 157.5876,  93.0143],\n",
       "          [141.1385,   0.7481, 288.7299,  92.8293],\n",
       "          [  9.5837,   1.7827, 295.3752, 296.3570],\n",
       "          [145.0972,   4.5466, 224.6366,  77.7609],\n",
       "          [205.8244,  52.5699, 282.7366, 233.7548],\n",
       "          [  5.5650,   1.2811, 297.4328, 294.3029],\n",
       "          [ 48.7882,  19.2601, 125.6417,  93.8596],\n",
       "          [  1.8802,   3.0585,  80.8676,  81.2123],\n",
       "          [223.7075,   1.4337, 299.6169,  80.9778],\n",
       "          [  1.8395,  84.9790,  98.8306, 202.5319],\n",
       "          [238.5367,  44.8935, 299.8582, 243.0473],\n",
       "          [ 20.9294,   8.0190,  58.3393,  72.0593],\n",
       "          [ 37.6510,   8.9292,  74.4354,  71.4251],\n",
       "          [178.4425,  19.2396, 256.0667,  93.7984],\n",
       "          [118.0724,  84.0069, 187.0082, 157.4930],\n",
       "          [202.4965,   1.1304, 289.5362, 161.4210],\n",
       "          [218.2451,  85.3029, 245.6610, 158.4250],\n",
       "          [101.0024,  34.8602, 173.2364, 108.6391],\n",
       "          [172.4661,  59.0756, 240.4586, 224.5742],\n",
       "          [ 54.4461,   9.8034,  89.8582,  71.4821],\n",
       "          [ 85.1510,  68.5434, 212.1624, 152.8489],\n",
       "          [ 63.5811,  88.3835, 161.0804, 197.8951],\n",
       "          [201.8103,  85.0744, 229.4454, 159.0333],\n",
       "          [ 74.3432,  85.5865, 101.7886, 158.8015],\n",
       "          [ 58.5282,  85.5575,  86.1358, 158.5946],\n",
       "          [102.8444,  98.9286, 170.9988, 173.8560],\n",
       "          [  6.0956, 156.3826,  82.5883, 299.9314],\n",
       "          [214.4175,   9.6031, 249.7369,  71.5890],\n",
       "          [ 42.6213, 127.3473, 113.8419, 286.3220],\n",
       "          [163.3912,  34.9135, 236.7543, 108.9456],\n",
       "          [ 73.9935,  20.8030, 101.7094,  94.7752],\n",
       "          [129.6711,  86.7946, 224.5178, 198.9275],\n",
       "          [ 12.8097,  66.9122, 143.0567, 153.8818],\n",
       "          [233.7363,  84.7997, 261.8459, 159.1146],\n",
       "          [230.1695,   9.0612, 266.8640,  72.1209],\n",
       "          [218.1999, 116.4529, 245.5617, 190.6018],\n",
       "          [201.8174,  20.4062, 229.9122,  95.7313],\n",
       "          [250.2949,   3.7929, 279.2755,  80.8239],\n",
       "          [121.7733,  85.5275, 150.3154, 158.8426],\n",
       "          [ 41.7524,  85.5274,  69.8118, 158.1456],\n",
       "          [105.8755,  85.6570, 134.1328, 159.1254],\n",
       "          [ 16.4789,  32.9189,  93.2821, 109.5887],\n",
       "          [ 86.6743,  27.0973, 121.7898,  86.6545],\n",
       "          [ 90.1442,  85.5534, 117.9141, 159.0118],\n",
       "          [ 35.3686,  99.2805, 107.8494, 173.4510],\n",
       "          [121.6563,  20.5143, 150.4722,  94.0772],\n",
       "          [  4.7342,  39.9313, 165.9786, 115.7681],\n",
       "          [137.5843,  85.6673, 166.1195, 158.9601],\n",
       "          [ 86.8690,  83.9569, 155.4493, 157.2133],\n",
       "          [137.5293,  20.4759, 166.3980,  94.5336],\n",
       "          [ 58.8027, 116.0040,  86.2314, 190.6895],\n",
       "          [185.7407,  20.5265, 214.6978,  94.7696],\n",
       "          [105.5916,  20.7802, 134.1643,  94.2890],\n",
       "          [118.8495, 115.0150, 186.4869, 189.6757],\n",
       "          [153.3643,  20.2750, 182.6170,  94.6863],\n",
       "          [ 50.8222,  92.1530, 278.5846, 227.9620],\n",
       "          [128.8131,  39.5603, 293.7282, 116.4012],\n",
       "          [169.4366,  20.3055, 198.5248,  94.7058],\n",
       "          [ 85.6221,  51.7365, 156.5925, 124.5284],\n",
       "          [ 74.5420, 116.0422, 101.7081, 190.6605],\n",
       "          [ 51.4385,  84.5204, 123.4111, 157.6514],\n",
       "          [ 58.4215,  36.4492,  86.0567, 110.1490],\n",
       "          [  7.3457,   3.9424,  37.2756,  83.3404],\n",
       "          [153.3565,  85.5711, 182.2992, 158.9750],\n",
       "          [ 41.8425, 115.8692,  69.5845, 190.2624],\n",
       "          [169.4141,  85.8152, 198.1090, 158.5737],\n",
       "          [ 38.3322,  42.1657,  73.8626, 103.0182],\n",
       "          [106.5645,  70.1046, 183.9409, 209.3506],\n",
       "          [233.7309, 115.9328, 261.9811, 191.1289],\n",
       "          [ 11.2889,   5.4049, 293.1689, 291.8522],\n",
       "          [  6.8083,   0.0000, 296.3820, 295.5557],\n",
       "          [  5.5650,   1.2811, 297.4328, 294.3029],\n",
       "          [ 11.2889,   5.4049, 293.1689, 291.8522],\n",
       "          [ 64.8494, 126.7306, 259.5463, 300.0000],\n",
       "          [ 64.8494, 126.7306, 259.5463, 300.0000],\n",
       "          [  9.5837,   1.7827, 295.3752, 296.3570],\n",
       "          [ 11.2889,   5.4049, 293.1689, 291.8522],\n",
       "          [ 95.1804,   1.4204, 232.0790, 207.9131],\n",
       "          [ 50.8222,  92.1530, 278.5846, 227.9620]], grad_fn=<StackBackward0>),\n",
       "  'scores': tensor([0.0475, 0.0469, 0.0436, 0.0433, 0.0421, 0.0405, 0.0394, 0.0384, 0.0379,\n",
       "          0.0376, 0.0374, 0.0355, 0.0351, 0.0334, 0.0334, 0.0332, 0.0321, 0.0319,\n",
       "          0.0314, 0.0296, 0.0294, 0.0290, 0.0283, 0.0280, 0.0279, 0.0279, 0.0276,\n",
       "          0.0266, 0.0262, 0.0262, 0.0255, 0.0253, 0.0249, 0.0249, 0.0247, 0.0247,\n",
       "          0.0246, 0.0242, 0.0238, 0.0238, 0.0232, 0.0229, 0.0227, 0.0227, 0.0227,\n",
       "          0.0226, 0.0225, 0.0225, 0.0224, 0.0223, 0.0223, 0.0221, 0.0220, 0.0219,\n",
       "          0.0219, 0.0216, 0.0215, 0.0214, 0.0214, 0.0211, 0.0211, 0.0210, 0.0210,\n",
       "          0.0210, 0.0210, 0.0208, 0.0207, 0.0206, 0.0206, 0.0206, 0.0205, 0.0205,\n",
       "          0.0205, 0.0205, 0.0204, 0.0204, 0.0204, 0.0204, 0.0203, 0.0203, 0.0203,\n",
       "          0.0203, 0.0202, 0.0200, 0.0200, 0.0199, 0.0198, 0.0198, 0.0191, 0.0165,\n",
       "          0.0152, 0.0118, 0.0116, 0.0106, 0.0104, 0.0104, 0.0102, 0.0102],\n",
       "         grad_fn=<IndexBackward0>),\n",
       "  'labels': tensor([ 1,  1,  1,  1,  1, 28,  1,  1, 61,  1,  1,  1,  1,  1,  1,  1,  5,  1,\n",
       "           1,  1,  1, 38,  1,  1, 65,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "           1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "           1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "           1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, 16, 52,\n",
       "           9, 84,  5, 35, 35, 32, 52, 35])},\n",
       " {'boxes': tensor([[ 94.0012,   4.7160, 299.1759, 148.2873],\n",
       "          [  6.7545,   4.2179, 394.2689, 492.0790],\n",
       "          [ 39.9891,  14.3616, 160.2946, 243.2369],\n",
       "          [ 88.2525,   4.0841, 342.9223, 297.7414],\n",
       "          [177.7826,  13.8455, 290.4613, 242.8934],\n",
       "          [ 11.8300,   0.0000, 390.2942, 495.7654],\n",
       "          [135.9807,  63.6382, 290.9042, 455.9232],\n",
       "          [ 12.8713,   4.0454, 204.2934, 153.4365],\n",
       "          [135.4124,  15.8081, 247.9891, 244.8462],\n",
       "          [ 94.1541,  18.0541, 205.3745, 242.8498],\n",
       "          [150.3596,  52.9133, 335.4983, 197.0501],\n",
       "          [  7.4558,   9.2907, 114.3417, 273.8677],\n",
       "          [  2.0775,  46.6186, 124.6745, 479.2024],\n",
       "          [226.7677,   5.8687, 327.2483, 261.6362],\n",
       "          [  3.3688,   6.4689, 398.4479, 488.3636],\n",
       "          [ 60.0805,  99.0692, 150.6262, 370.8100],\n",
       "          [184.4829,   2.0848, 386.0712, 152.2488],\n",
       "          [ 13.8628,  90.6063, 241.7591, 428.9223],\n",
       "          [134.6196,  32.5936, 230.1373, 155.4451],\n",
       "          [ 40.0130,  74.0211, 271.1460, 188.7020],\n",
       "          [  3.3688,   6.4689, 398.4479, 488.3636],\n",
       "          [186.4206,  88.7986, 400.0000, 431.1902],\n",
       "          [  2.5313, 140.8404, 132.9868, 334.9435],\n",
       "          [197.2922,  32.4691, 294.9928, 154.8427],\n",
       "          [152.9444,   7.6817, 254.9333, 129.8493],\n",
       "          [  3.3688,   6.4689, 398.4479, 488.3636],\n",
       "          [ 22.0972,  29.0770, 123.8284, 156.4307],\n",
       "          [273.3014,  32.7837, 379.2762, 325.7856],\n",
       "          [109.8953, 118.5775, 282.2630, 254.1026],\n",
       "          [ 68.1998,  33.4174, 166.7156, 156.1116],\n",
       "          [108.3609,  95.1180, 193.6445, 367.8624],\n",
       "          [ 18.8529, 112.7861, 192.8553, 255.7755],\n",
       "          [177.1138,  57.1499, 271.6812, 179.6274],\n",
       "          [108.5615,   0.0000, 191.9693, 156.7723],\n",
       "          [238.5945,  32.7862, 339.8106, 154.1889],\n",
       "          [231.6623,  98.4059, 320.5659, 371.4635],\n",
       "          [ 50.6674,  15.8280,  98.7118, 118.9983],\n",
       "          [  6.7545,   4.2179, 394.2689, 492.0790],\n",
       "          [ 28.3169,  14.6257,  77.2267, 119.3797],\n",
       "          [317.1505,  79.2180, 400.0000, 396.3159],\n",
       "          [275.0879, 152.3796, 375.2310, 437.4796],\n",
       "          [156.3788, 141.3879, 249.5134, 260.9418],\n",
       "          [290.2476,   7.5523, 327.9516, 132.7730],\n",
       "          [ 55.6360, 141.2216,  93.1566, 264.7679],\n",
       "          [298.6955,   3.1044, 398.9687, 134.3395],\n",
       "          [ 78.1922, 141.3816, 114.7932, 264.5706],\n",
       "          [268.9203,  33.5956, 306.3738, 158.7170],\n",
       "          [ 73.5382,  43.9640, 119.6282, 145.1722],\n",
       "          [162.5518, 142.0942, 199.9858, 265.1766],\n",
       "          [  9.4853, 257.2954, 111.6713, 500.0000],\n",
       "          [141.3048, 142.0580, 178.3890, 265.8643],\n",
       "          [ 57.7464, 210.2455, 151.7843, 478.1732],\n",
       "          [ 99.3050, 141.7920, 135.6150, 265.4817],\n",
       "          [136.1791, 166.0615, 228.9599, 287.9824],\n",
       "          [219.3059,  58.6940, 314.7731, 179.3065],\n",
       "          [ 63.0090, 173.9012, 241.0072, 305.4700],\n",
       "          [115.3698, 140.7122, 207.5887, 260.7376],\n",
       "          [ 47.5229, 140.3730, 143.9307, 261.4070],\n",
       "          [310.8954,   7.2962, 350.3932, 132.9931],\n",
       "          [147.6692,  93.7021, 236.7098, 367.1529],\n",
       "          [ 63.4605, 152.5535, 370.3479, 375.3751],\n",
       "          [170.6774, 148.8677, 300.6353, 326.1476],\n",
       "          [156.0757,  86.5233, 249.9717, 207.6407],\n",
       "          [120.1916, 142.0217, 157.0260, 265.7825],\n",
       "          [162.2374,  34.2927, 200.3222, 157.9357],\n",
       "          [183.6361, 142.5448, 221.1742, 265.1647],\n",
       "          [247.8306,  33.8605, 286.0395, 158.1927],\n",
       "          [ 34.9490, 140.4673,  71.6748, 265.8750],\n",
       "          [135.6579, 112.0669, 228.4731, 234.4216],\n",
       "          [ 99.6698, 193.4867, 135.7685, 318.5303],\n",
       "          [141.0766,  34.5556, 178.7742, 158.4604],\n",
       "          [141.5876, 193.3129, 178.2434, 320.0159],\n",
       "          [ 56.1055,  59.7518,  93.4275, 184.4465],\n",
       "          [ 98.9148,  35.2883, 135.6261, 158.4776],\n",
       "          [183.5204,  34.0067, 221.6207, 158.2253],\n",
       "          [204.6837,  33.6497, 242.8711, 158.2956],\n",
       "          [226.2865,  33.7497, 264.1595, 158.3320],\n",
       "          [204.9002, 142.9122, 242.6724, 264.8622],\n",
       "          [ 78.5457, 193.1494, 114.7786, 317.9143],\n",
       "          [229.0615,  44.6873, 396.7824, 202.3612],\n",
       "          [120.4976, 193.8345, 157.0004, 319.3335],\n",
       "          [333.0863,   6.9758, 372.5779, 132.8798],\n",
       "          [ 55.8899, 192.5818,  93.0069, 317.3964],\n",
       "          [119.7888,  35.2573, 157.3113, 158.5609],\n",
       "          [310.9031, 480.8867, 319.8461, 499.1125],\n",
       "          [321.8458, 481.9809, 330.3344, 499.2627],\n",
       "          [290.7720, 168.0026, 326.9980, 292.9876],\n",
       "          [ 43.1496,  54.8440, 106.3643, 133.5896],\n",
       "          [114.7348,  86.7969, 207.9205, 207.7543],\n",
       "          [162.6258,  85.9439, 199.7839, 211.8795],\n",
       "          [ 78.0947, 223.2662, 348.0267, 500.0000],\n",
       "          [  3.3688,   6.4689, 398.4479, 488.3636],\n",
       "          [104.6859,  97.2818, 326.8268, 419.5515],\n",
       "          [  3.3688,   6.4689, 398.4479, 488.3636],\n",
       "          [  3.3688,   6.4689, 398.4479, 488.3636],\n",
       "          [ 51.7914, 195.3885, 371.4781, 500.0000],\n",
       "          [180.6944, 290.1955, 386.5689, 490.2451]], grad_fn=<StackBackward0>),\n",
       "  'scores': tensor([0.0464, 0.0460, 0.0420, 0.0411, 0.0368, 0.0367, 0.0366, 0.0363, 0.0362,\n",
       "          0.0357, 0.0334, 0.0327, 0.0320, 0.0304, 0.0303, 0.0301, 0.0287, 0.0282,\n",
       "          0.0282, 0.0260, 0.0255, 0.0255, 0.0252, 0.0252, 0.0251, 0.0240, 0.0239,\n",
       "          0.0238, 0.0231, 0.0224, 0.0223, 0.0219, 0.0218, 0.0217, 0.0217, 0.0207,\n",
       "          0.0206, 0.0205, 0.0204, 0.0203, 0.0203, 0.0203, 0.0201, 0.0201, 0.0200,\n",
       "          0.0199, 0.0197, 0.0194, 0.0194, 0.0193, 0.0192, 0.0191, 0.0190, 0.0190,\n",
       "          0.0190, 0.0188, 0.0186, 0.0185, 0.0185, 0.0184, 0.0183, 0.0183, 0.0183,\n",
       "          0.0182, 0.0182, 0.0181, 0.0181, 0.0180, 0.0179, 0.0179, 0.0179, 0.0178,\n",
       "          0.0178, 0.0178, 0.0178, 0.0178, 0.0177, 0.0176, 0.0176, 0.0176, 0.0174,\n",
       "          0.0174, 0.0173, 0.0172, 0.0172, 0.0172, 0.0171, 0.0171, 0.0171, 0.0169,\n",
       "          0.0149, 0.0138, 0.0122, 0.0115, 0.0114, 0.0109, 0.0105],\n",
       "         grad_fn=<IndexBackward0>),\n",
       "  'labels': tensor([ 1,  5,  1,  1,  1, 28,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "           1,  1, 65,  1,  1,  1,  1, 38,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "           1, 61,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "           1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "           1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "           5,  9, 35, 16, 84, 35,  5])}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [torch.rand(3, 300, 300), torch.rand(3, 500, 400)]\n",
    "predictions = quantized_model_int8(x)\n",
    "predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
